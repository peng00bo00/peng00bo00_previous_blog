---
layout: article
title: Shape Analysis课程笔记18-Optimal Transport
tags: ["CG", "Geometry Processing", "Shape Analysis"]
key: SA-17
aside:
  toc: true
sidebar:
  nav: SA
---

> 这个系列是[MIT 6.838: Shape Analysis](https://groups.csail.mit.edu/gdpgroup/6838_spring_2021.html)的同步课程笔记。本课程会介绍几何方法在图形学、机器学习、计算机视觉、医疗图像以及建筑设计等相关领域的原理和应用。本节主要介绍最优运输问题。
<!--more-->

## Introduction to Optimal Transport

**最优运输(optimal transport)**是使用几何视角来研究概率分布的学科，它的一个基本问题是如何比较两个概率分布，或者说如何把一个概率分布通过运输转换成另一个分布。

<div align=center>
<img src="https://i.imgur.com/B4OlZhE.png" width="80%">
</div>

人们对最优运输问题的研究可以追溯到19世纪中期，实际上到今天为止仍然有很多数学家在研究最优运输问题。

<div align=center>
<img src="https://i.imgur.com/73EJ0FG.png" width="80%">
</div>

限于课时有限，本节课只会简单地介绍最优运输的概念和一些常见的应用场景。关于最优运输理论更加系统的介绍可以参考专业教材。

<div align=center>
<img src="https://i.imgur.com/3eJo1i3.png" width="80%">
</div>

### Probability as Geometry

在最优运输理论中，我们会把概率分布看做是某种几何对象。

<div align=center>
<img src="https://i.imgur.com/AccS39K.png" width="80%">
<img src="https://i.imgur.com/LbBFp31.png" width="80%">
<img src="https://i.imgur.com/wGPYD0R.png" width="80%">
</div>

### How We Compute Distance

在这种观察下我们首先要考虑如何计算两个概率分布的"距离"，常用的距离度量包括$L^p$范数或是**KL散度(KL divergence)**等：

$$
\Vert p_1 - p_2 \Vert_p = \bigg( \int \vert p_1(x) - p_2(x) \vert^p \ dx \bigg)^{\frac{1}{p}}
$$

$$
\text{KL} (p_1 \Vert p_2) = \int p_1(x) \ \log \frac{p_1(x)}{p(x)} \ dx
$$

<div align=center>
<img src="https://i.imgur.com/5sIdNH0.png" width="80%">
</div>

然而这些度量函数的缺陷在于当概率分布没有重叠区域时就无法对概率分布进行区分了。换句话说当$p_1$和$p_2$互相分离时，无论如何移动两个概率分布$L^p$范数或者KL散度给出的距离是相同的。

<div align=center>
<img src="https://i.imgur.com/7AW0oih.png" width="80%">
</div>

因此我们可以认为$L^p$范数以及KL散度实际上度量的是两个概率分布之间的重叠程度，而不是它们之间的距离。

<div align=center>
<img src="https://i.imgur.com/pj874WQ.png" width="80%">
</div>

### Alternative Idea

而在最优运输问题则关心概率分布之间的"距离"。我们可以把两个概率分布想象成两个沙堆，而我们的目标是使用最小的代价把一个沙堆通过运输来得到另一个沙堆。

<div align=center>
<img src="https://i.imgur.com/jjhy0Fg.png" width="80%">
<img src="https://i.imgur.com/LUguLHQ.png" width="80%">
</div>

记$\pi(x, y)$表示运输过程，它需要满足相应的约束条件。

<div align=center>
<img src="https://i.imgur.com/Y8EP7nH.png" width="80%">
</div>

### Kantorovich Problem

接着引入代价函数$c(x, y)$我们就可以定义最优运输问题的优化目标$\text{OT}(\mu, \nu, c)$，如此定义的最优运输问题称为**Kantorovich问题(Kantorovich problem)**。

<div align=center>
<img src="https://i.imgur.com/IZR4DGO.png" width="80%">
</div>

### p-Wasserstein Distance

实际上几何处理中的**p-Wasserstein距离(p-Wasserstein Distance)**也可以看做是一种Kantorovich问题，其代价函数为曲面上两点之间的测地距离。当$p=1$时p-Wasserstein距离有着完全符合Kantorovich问题的形式。

<div align=center>
<img src="https://i.imgur.com/ewORnW8.png" width="80%">
<img src="https://i.imgur.com/RNcsxjE.png" width="80%">
</div>

更进一步，1-Wasserstein距离和2-Wasserstein距离在一维情况下具有解析形式的解。

<div align=center>
<img src="https://i.imgur.com/aMOn5wO.png" width="80%">
</div>

而在离散情况下，p-Wasserstein距离则可以通过**线性规划(linear programming, LP)**的方式来求解。

<div align=center>
<img src="https://i.imgur.com/SeEuRo8.png" width="80%">
</div>

### Semidiscrete Transport

除了连续和离散的情况，最优运输问题还会考虑**半离散(semidiscrete)**的情况。

<div align=center>
<img src="https://i.imgur.com/frIuUhU.png" width="80%">
</div>

### Monge Formulation

还需要说明的是最优运输问题除了可以使用Kantorovich问题进行定义外，还可以使用**Monge形式(Monge formulation)**来进行定义。不过需要说明的是并不是所有最优运输问题的都可以转换为Monge形式。

<div align=center>
<img src="https://i.imgur.com/PmZmTmO.png" width="80%">
</div>

### Many Formulas

最优运输问题有很多不同的理解方式。

#### Discrete Transport Problem

<div align=center>
<img src="https://i.imgur.com/xRCcMF7.png" width="80%">
</div>

#### Kantorovich Duality

利用对偶性，最小化运输代价也可以理解为最大化定价。

<div align=center>
<img src="https://i.imgur.com/ButX9Dz.png" width="80%">
</div>

#### Flow-Based W2

对于$p=2$的p-Wasserstein距离，我们可以把原始概率密度和目标概率密度分别理解为气体在$t=0$和$t=1$时刻的分布，这样最优运输问题就等价于流体力学中的运输现象。

<div align=center>
<img src="https://i.imgur.com/tCXPcqw.png" width="80%">
</div>

## Applications

很多机器学习中的问题都可以理解为某种最优运输问题，这样就可以利用最优运输问题的标准解法来进行处理。

<div align=center>
<img src="https://i.imgur.com/l0bXLfA.png" width="80%">
</div>

运筹学中的很多问题天然符合最优运输问题的定义，显然我们也可以使用相关的方法来求解。

<div align=center>
<img src="https://i.imgur.com/ndOWmZa.png" width="80%">
</div>

在NLP中对词嵌入的比较也可以使用最优运输的相关理论。

<div align=center>
<img src="https://i.imgur.com/jtvxQ3d.png" width="80%">
</div>

在CV中最优运输理论可以帮助我们处理各种配准问题。

<div align=center>
<img src="https://i.imgur.com/h8GC83F.png" width="80%">
</div>

我们甚至可以利用最优运输理论来辅助设计复杂的光学系统。

<div align=center>
<img src="https://i.imgur.com/6f7tTSS.png" width="80%">
</div>

对于各种形式的插值以及概率分布的变换问题，我们都可以考虑从最优运输的角度进行理解。

<div align=center>
<img src="https://i.imgur.com/D7HC8kb.png" width="80%">
<img src="https://i.imgur.com/I2LL3dw.png" width="80%">
<img src="https://i.imgur.com/npAJ50K.png" width="80%">
<img src="https://i.imgur.com/ydSkGsf.png" width="80%">
<img src="https://i.imgur.com/tVWeEer.png" width="80%">
</div>

## Discrete Transport

当我们需要求解最优运输问题时，不同的建模方式会产生不同的求解算法。当然这些算法各有侧重，并不存在一种能够解决一切问题的算法。

<div align=center>
<img src="https://i.imgur.com/S8LCTld.png" width="80%">
</div>

### Entropic Regularization

**entropic regularization**是求解最优运输问题最流行的算法，此时我们需要在原始优化目标中添加运输$T$的熵作为正则项。

<div align=center>
<img src="https://i.imgur.com/JqiWNnu.png" width="80%">
</div>

可以证明添加了正则项后的优化目标函数等价于KL散度，这样可以得到最优运输的解析解。

<div align=center>
<img src="https://i.imgur.com/s30ToFA.png" width="80%">
</div>

而要满足运输项$T$的约束则可以使用Sinkhorn算法进行计算，它相当于把解在两个集合上反复进行投影。

<div align=center>
<img src="https://i.imgur.com/asVHCEL.png" width="80%">
</div>

<div align=center>
<img src="https://i.imgur.com/HC72tAf.png" width="80%">
<img src="https://i.imgur.com/9hlDCnk.png" width="80%">
</div>

### Eulerian Optimization

<div align=center>
<img src="https://i.imgur.com/4AXHUPF.png" width="80%">
<img src="https://i.imgur.com/W2qWwIS.png" width="80%">
</div>

### Semidiscrete Optimization

<div align=center>
<img src="https://i.imgur.com/TygOYYB.png" width="80%">
<img src="https://i.imgur.com/tNmLk60.png" width="80%">
</div>

<div align=center>
<img src="https://i.imgur.com/Fe6N8g6.png" width="80%">
</div>

<div align=center>
<img src="https://i.imgur.com/7UX7bS3.png" width="80%">
<img src="https://i.imgur.com/Ii24sDG.png" width="80%">
<img src="https://i.imgur.com/vV91U7r.png" width="80%">
</div>

## Extensions & Frontiers

基于最优传输的概念我们可以定义函数之间的重心坐标以实现插值。

<div align=center>
<img src="https://i.imgur.com/6t2JOLm.png" width="80%">
</div>

这样的方法也可以结合到贝叶斯推断中，从而实现对分布的插值。

<div align=center>
<img src="https://i.imgur.com/ydHtDoj.png" width="80%">
</div>

对于各种匹配的问题也可以借用最优运输的框架来进行处理。

<div align=center>
<img src="https://i.imgur.com/3PHHrAd.png" width="80%">
<img src="https://i.imgur.com/MIigZJi.png" width="80%">
</div>

最优运输理论还可以用来求解微分方程。

<div align=center>
<img src="https://i.imgur.com/mLETlrD.png" width="80%">
</div>

当然，最优运输理论在几何处理中也有非常广泛的应用。

<div align=center>
<img src="https://i.imgur.com/Ax08nHK.png" width="80%">
</div>

<div align=center>
<img src="https://i.imgur.com/AKGw1Km.png" width="80%">
</div>

## Reference

- [Lecture 19: Optimal transport](https://www.youtube.com/watch?v=MSbvkhAR0VY&list=PLQ3UicqQtfNtUcdTMLgKSTTOiEsCw2VBW&index=27)
- [Optimal Transport](https://groups.csail.mit.edu/gdpgroup/assets/6838_spring_2021/13_optimal_transport.pdf)