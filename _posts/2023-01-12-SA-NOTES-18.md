---
layout: article
title: Shape Analysis课程笔记18-Optimal Transport
tags: ["CG", "Geometry Processing", "Shape Analysis"]
key: SA-17
aside:
  toc: true
sidebar:
  nav: SA
---

> 这个系列是[MIT 6.838: Shape Analysis](https://groups.csail.mit.edu/gdpgroup/6838_spring_2021.html)的同步课程笔记。本课程会介绍几何方法在图形学、机器学习、计算机视觉、医疗图像以及建筑设计等相关领域的原理和应用。本节主要介绍最优运输问题。
<!--more-->

## Introduction to Optimal Transport

**最优运输(optimal transport)**是使用几何视角来研究概率分布的学科，它的一个基本问题是如何比较两个概率分布，或者说如何把一个概率分布通过运输转换成另一个分布。

<div align=center>
<img src="https://i.imgur.com/B4OlZhE.png" width="80%">
</div>

人们对最优运输问题的研究可以追溯到19世纪中期，实际上到今天为止仍然有很多数学家在研究最优运输问题。

<div align=center>
<img src="https://i.imgur.com/73EJ0FG.png" width="80%">
</div>

限于课时有限，本节课只会简单地介绍最优运输的概念和一些常见的应用场景。关于最优运输理论更加系统的介绍可以参考专业教材。

<div align=center>
<img src="https://i.imgur.com/3eJo1i3.png" width="80%">
</div>

### Probability as Geometry

在最优运输理论中，我们会把概率分布看做是某种几何对象。

<div align=center>
<img src="https://i.imgur.com/AccS39K.png" width="80%">
<img src="https://i.imgur.com/LbBFp31.png" width="80%">
<img src="https://i.imgur.com/wGPYD0R.png" width="80%">
</div>

### How We Compute Distance

在这种观察下我们首先要考虑如何计算两个概率分布的"距离"，常用的距离度量包括$L^p$范数或是**KL散度(KL divergence)**等：

$$
\Vert p_1 - p_2 \Vert_p = \bigg( \int \vert p_1(x) - p_2(x) \vert^p \ dx \bigg)^{\frac{1}{p}}
$$

$$
\text{KL} (p_1 \Vert p_2) = \int p_1(x) \ \log \frac{p_1(x)}{p(x)} \ dx
$$

<div align=center>
<img src="https://i.imgur.com/5sIdNH0.png" width="80%">
</div>

然而这些度量函数的缺陷在于当概率分布没有重叠区域时就无法对概率分布进行区分了，换句话说当$p_1$和$p_2$互相分离时$L^p$范数或者KL散度给出的距离是相同的。

<div align=center>
<img src="https://i.imgur.com/7AW0oih.png" width="80%">
</div>

因此我们可以认为$L^p$范数以及KL散度实际上度量的是两个概率分布之间的重叠程度，而不是它们之间的距离。

<div align=center>
<img src="https://i.imgur.com/pj874WQ.png" width="80%">
</div>

### Alternative Idea

而在最优运输问题则关心概率分布之间的"距离"。我们可以把两个概率分布想象成两个沙堆，而我们的目标是使用最小的代价把一个沙堆通过运输来得到另一个沙堆。

<div align=center>
<img src="https://i.imgur.com/jjhy0Fg.png" width="80%">
<img src="https://i.imgur.com/LUguLHQ.png" width="80%">
</div>

记$\pi(x, y)$表示运输过程，它需要满足相应的约束条件。

<div align=center>
<img src="https://i.imgur.com/Y8EP7nH.png" width="80%">
</div>

### Kantorovich Problem

接着引入代价函数$c(x, y)$我们就可以定义最优运输问题的优化目标$\text{OT}(\mu, \nu, c)$，如此定义的最优运输问题称为**Kantorovich问题(Kantorovich problem)**。

<div align=center>
<img src="https://i.imgur.com/IZR4DGO.png" width="80%">
</div>

### p-Wasserstein Distance

实际上几何处理中的**p-Wasserstein距离(p-Wasserstein Distance)**也可以看做是一种Kantorovich问题，其代价函数为曲面上两点之间的测地距离。当$p=1$时p-Wasserstein距离有着完全符合Kantorovich问题的形式。

<div align=center>
<img src="https://i.imgur.com/ewORnW8.png" width="80%">
<img src="https://i.imgur.com/RNcsxjE.png" width="80%">
</div>

更进一步，1-Wasserstein距离和2-Wasserstein距离在一维情况下具有解析形式的解。

<div align=center>
<img src="https://i.imgur.com/aMOn5wO.png" width="80%">
</div>

而在离散情况下，p-Wasserstein距离则可以通过**线性规划(linear programming, LP)**的方式来求解。

<div align=center>
<img src="https://i.imgur.com/SeEuRo8.png" width="80%">
</div>

### Semidiscrete Transport

除了连续和离散的情况，最优运输问题还会考虑**半离散(semidiscrete)**的情况。

<div align=center>
<img src="https://i.imgur.com/frIuUhU.png" width="80%">
</div>

### Monge Formulation

还需要说明的是最优运输问题除了可以使用Kantorovich问题进行定义外，还可以使用**Monge形式(Monge formulation)**来进行定义。不过需要注意的是并不是所有最优运输问题的都可以转换为Monge形式。

<div align=center>
<img src="https://i.imgur.com/PmZmTmO.png" width="80%">
</div>

## Applications

## Discrete Transport

### Entropic Regularization

### Eulerian Optimization

### Semidiscrete Optimization

## Extensions & Frontiers

## Reference

- [Lecture 19: Optimal transport](https://www.youtube.com/watch?v=MSbvkhAR0VY&list=PLQ3UicqQtfNtUcdTMLgKSTTOiEsCw2VBW&index=27)
- [Optimal Transport](https://groups.csail.mit.edu/gdpgroup/assets/6838_spring_2021/13_optimal_transport.pdf)