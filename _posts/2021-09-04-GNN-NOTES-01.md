---
layout: article
title: 深蓝学院-GNN课程笔记01-图论基础
tags: ["深蓝学院", "GNN"]
key: 深蓝学院-GNN-01
aside:
  toc: true
sidebar:
  nav: 深蓝学院-GNN
---

> 这个系列是深蓝学院[图深度学习理论与实践](https://www.shenlanxueyuan.com/my/course/376)的同步课程笔记。课程内容涉及图深度学习的基础理论与应用，本节主要图论的基础知识。
<!--more-->

## 图的表示

一个**图(Graph)**可以表示为$$G = \{ V, E \}$$，其中$$V = \{ v_1, ... , v_N \}$$是节点的集合, $$E = \{ e_1, ... , e_M \}$$是边的集合。

<div align=center>
<img src="https://i.imgur.com/GtXb6SN.png" width="40%">
</div>

一个图可以用**邻接矩阵(adjacency matrix)**来存储。给定一个图$$G = \{ V, E \}$$，对应的邻接矩阵可以表示为$$A = \{ 0, 1 \}^{N \times N}$$，如果$v_i$和$v_j$相邻则$A_{ij} = 1$否则$A_{ij} = 0$。显然无向图的邻接矩阵一定是对称的，上图对应的邻接矩阵为：

$$
A =
\begin{bmatrix}
0 & 1 & 0 & 1 & 1 \\
1 & 0 & 1 & 0 & 0 \\
0 & 1 & 0 & 0 & 1 \\
1 & 0 & 0 & 0 & 1 \\
1 & 0 & 1 & 1 & 0 \\
\end{bmatrix}
$$

## 图的性质

### 度

图的性质有很多，其中最基本的性质是节点的**度(degree)**，它表示与该节点相邻的其他节点的数目：

$$
d(v_i) = \sum_{v_i \in V} \mathbb{1}_E (\{ v_i, v_j \}) = \sum_{j=1}^N A_{ij}
$$

$$
\mathbb{1}_E (\{ v_i, v_j \}) = 
\left\{
\begin{aligned}
& 1, & & (v_i, v_j) \in E \\
& 0, & & \text{otherwise}
\end{aligned}
\right.
$$

<div align=center>
<img src="https://i.imgur.com/Im1obVi.png" width="40%">
</div>

同时，图上所有节点度的和(邻接矩阵中非零元素的个数)等于图上边数量的2倍：

$$
\sum_{v_i \in V} d(v_i) = 2 \vert E \vert
$$

在度的基础上我们可以定义**邻域(neighborhood)** $N(v_i)$，它表示所有与节点$v_i$相邻的节点构成的集合。显然邻域$N(v_i)$中元素的个数等于节点的度：

$$
d(v_i) = \vert N(v_i) \vert
$$

<div align=center>
<img src="https://i.imgur.com/6IlJTE5.png" width="40%">
</div>

### 连通度

我们定义**途径(walk)**是节点与边的交替序列，从一个节点开始，以一个节点结束，其中每条边与紧邻的节点相连。途径的长度定义为途径中包含的边的数量。

<div align=center>
<img src="https://i.imgur.com/ueE9u8T.png" width="40%">
</div>

在途径的基础上可以定义**迹(trail)**和**路径(path)**，其中迹是边各不相同的途径，而路径是节点各不相同的途径。换句话说，迹中不能有相同的边儿路径中不能有相同的节点。以下图为例，$(v_1, e_4, v_4, e_5, v_5, e_6, v_1, e_1, v_2)$是一条迹但不是路径，而$(v_1, e_4, v_4, e_5, v_5, e_3, v_3)$则是一条路径。

<div align=center>
<img src="https://i.imgur.com/ueE9u8T.png" width="41%">
<img src="https://i.imgur.com/tmjeUYH.png" width="40%">
</div>

给定一个图，如果图中的任意两个节点之间都至少存在一条路径，则称这个图是一个**连通图(connected graph)**。对于下图所表示的图，如果只考虑左半部分则它是一个连通图，如果把整个图放在一起考虑则不是一个连通图。

<div align=center>
<img src="https://i.imgur.com/UpT1OJs.png" width="70%">
</div>

给定连通图中的任意两点，连接这两点的长度最小的路径被称为这两点之间的**最短路径(shortest path)**，最短路径的长度被称为两点间的距离。需要注意的是一对节点之间可能存在不止一条最短路径，如下图中$v_5$和$v_2$之间就存在2条最短路径。

<div align=center>
<img src="https://i.imgur.com/aAbz3s9.png" width="40%">
</div>

通过最短路径我们可以定义图的**直径(diameter)**为图上最远的两点间的距离，即所有最短路径中的最长路径的长度。

<div align=center>
<img src="https://i.imgur.com/C0Mqsom.png" width="40%">
</div>

### 中心性

节点的**中心性(centrality)**用来衡量节点在图上的重要程度，其中最基础的是**度中心性(degree centrality)**，它基于节点的度来测量它的中心性：

$$
c_d(v_i) = d(v_i) = \sum_{j=1}^N A_{ij}
$$

度中心性背后的思想在于与节点$v_i$相邻的节点越多，$v_i$在图上就越重要。

度中心性认为与节点$v_i$相邻的节点都具有相同的重要性，然而在实际中不同节点的重要性往往是不同的。在此基础上我们可以定义节点的**特征向量中心性(eigenvector centrality)**来考虑相邻节点的中心性对中心节点的贡献：

$$
c_e(v_i) = \frac{1}{\lambda} \sum_{j=1}^N A_{ij} c_e(v_j)
$$

其中$\lambda$为归一化系数。将上面的公式写成矩阵的形式不难发现特征向量中心性$c_e$实际上对应了连接矩阵$A$的特征向量，而$\lambda$为对应的特征值：

$$
\lambda c_e = A c_e
$$

显然对于给定的图可能存在多个不同的特征向量，实际中一般可取最大特征值的作为特征向量中心性。

类似地，可以定义**Katz中心性(Katz centrality)**为：

$$
c_k(v_i) = \alpha \sum_{j=1}^N A_{ij} c_k(v_j) + \beta
$$

其中常数$\beta$表示中心节点自身天然具有的重要性，而常数$\alpha$表示其他节点贡献的中心性相对于$\beta$的权重。将上面的公式写成矩阵的形式得到：

$$
c_k = \alpha A c_k + \beta
$$

$$
(I - \alpha A) c_k = \beta
$$

显然常数$\alpha$和$\beta$控制了Katz中心性的值，当$\alpha=\frac{1}{\lambda_{\text{max}}}$且$\beta = 0$时Katz中心性即为特征向量中心性。同时需要注意$\alpha$的选取：比较大的$\alpha$容易导致矩阵$I - \alpha A$出现病态的情况， 在实践中一般令$\alpha < \frac{1}{\lambda_{\text{max}}}$；而较小的$\alpha$会导致不同节点都具有相似的中心性，此时计算得到的中心性是没有意义的。

## 谱图论与图信号处理

## 复杂图