---
layout: article
title: Shape Analysis课程笔记17-Optimization on Manifolds
tags: ["CG", "Geometry Processing", "Shape Analysis"]
key: SA-17
aside:
  toc: true
sidebar:
  nav: SA
---

> 这个系列是[MIT 6.838: Shape Analysis](https://groups.csail.mit.edu/gdpgroup/6838_spring_2021.html)的同步课程笔记。本课程会介绍几何方法在图形学、机器学习、计算机视觉、医疗图像以及建筑设计等相关领域的原理和应用。本节主要介绍流形上的优化问题。
<!--more-->

## Optimization with a Manifold Constraint

在机器学习和计算机视觉中很多问题都可以建模为在流形上进行处理的优化问题。

<div align=center>
<img src="https://i.imgur.com/pOr7PYN.png" width="80%">
</div>

三维重建中对相机姿态的优化就是典型的例子：相机的旋转矩阵并不是任意的矩阵，它需要满足正交阵的约束。

<div align=center>
<img src="https://i.imgur.com/QDJ7kBQ.png" width="80%">
</div>

**冷冻电镜(Cryo-EM)**在重建分子的结构时也会遇到类似的问题。

<div align=center>
<img src="https://i.imgur.com/iYX9OAg.png" width="80%">
</div>

而对于如何优化传感器的布置，我们同样可以把它表示为一个优化问题，此时传感器的布置形式在刚体变换下是相互等价的。

<div align=center>
<img src="https://i.imgur.com/0o9mvS7.png" width="80%">
</div>

## Manifold Optimization Algorithms

### Typical Approach

在过去，处理这些问题的经典方法是把流形上的优化变量嵌入到高维空间中，然后求解高维的约束优化问题。比如说三维空间的旋转构成李群SO(3)，在优化旋转时可以先直接优化一个3×3的矩阵，然后再处理旋转矩阵的约束。

<div align=center>
<img src="https://i.imgur.com/MyyhGnR.png" width="80%">
</div>

然而这种处理方法的缺陷在于它往往会具有非常复杂的表达形式，使得求解过程变得非常困难。

<div align=center>
<img src="https://i.imgur.com/4y3dHrl.png" width="80%">
</div>

从几何上来看，求解这样的约束优化问题相当于在红色曲线上进行移动直到找到优化目标$f$的最优解。此时我们可以通过投影的方式进行处理，即先忽略约束直接求解无约束优化然后把找到的解投影到约束空间中。

<div align=center>
<img src="https://i.imgur.com/ovDs0hO.png" width="80%">
<img src="https://i.imgur.com/VdkyadX.png" width="80%">
</div>

当然投影过程往往也并不容易，尤其是在约束条件比较复杂的时候。

<div align=center>
<img src="https://i.imgur.com/L3oK0S1.png" width="80%">
</div>

### Instrinsic Perspective

因此更现代的处理方法是结合流形自身的结构，利用流形自身的性质来进行求解。

<div align=center>
<img src="https://i.imgur.com/CidP5EK.png" width="80%">
<img src="https://i.imgur.com/rzyhVV2.png" width="80%">
</div>

从更高的视角来看这样的方法相当于直接在流形上进行优化，从而无需考虑复杂的约束条件。

<div align=center>
<img src="https://i.imgur.com/IrCj1eC.png" width="80%">
</div>

### Gradient Descent

以**梯度下降(gradient descent)**为例，我们常用的梯度下降公式都假定了变量位于欧式空间中。

<div align=center>
<img src="https://i.imgur.com/75Y25Cg.png" width="80%">
<img src="https://i.imgur.com/WnAqKeI.png" width="80%">
</div>

而在流形上，我们需要先把欧式空间上的梯度转换为切空间上的向量，然后按照切向量的方向沿着测地线进行移动从而实现优化过程。

<div align=center>
<img src="https://i.imgur.com/5Oauy5L.png" width="80%">
</div>

当我们考虑了流形的结构时往往会得到更好的优化算法，此时的约束优化问题也一般会具有更优雅的数学性质。

<div align=center>
<img src="https://i.imgur.com/WgF3Po1.png" width="80%">
</div>

需要说明的是流形上的优化是一门非常复杂的学科，想要更系统的学习可以参考专业的书籍或是优化软件手册。

<div align=center>
<img src="https://i.imgur.com/kBt95Pc.png" width="80%">
<img src="https://i.imgur.com/lytoQrY.png" width="80%">
<img src="https://i.imgur.com/EzuQICQ.png" width="80%">
</div>

### Tangent Space

在继续介绍流形上的优化算法前我们先回忆一下方向导数以及切空间的概念。

<div align=center>
<img src="https://i.imgur.com/LET3ZvD.png" width="80%">
<img src="https://i.imgur.com/SzSWn4M.png" width="80%">
</div>

在切空间的基础上，优化目标$f$的梯度实际上对应了切空间上的切向量。在整个流形上，这些切向量构成了一个梯度场。

<div align=center>
<img src="https://i.imgur.com/Tdl5qH0.png" width="80%">
</div>

### Exponential Map

流形上的**指数映射(exponential map)**定义了从起点$\mathbf{p}$出发沿切向量$\mathbf{v}$方向的测地线移动的过程。

<div align=center>
<img src="https://i.imgur.com/bNjr6sE.png" width="80%">
</div>

当然流形上测地线的计算往往是非常困难的，我们几乎无法给出一般流形上测地线的解析形式。

<div align=center>
<img src="https://i.imgur.com/vPwH7bI.png" width="80%">
</div>

### Retraction

不过我们可以利用**retraction**来放松测地线的约束，它是对指数映射的一种局部近似。

<div align=center>
<img src="https://i.imgur.com/AbCjXg0.png" width="80%">
</div>

### Riemannian Manifold

除此之外，我们还需要引入**黎曼流形(Riemannian manifold)**的概念。简单来说，当流形$\mathcal{M}$上配备了内积$g_\mathbf{p}$后就得到了黎曼流形。

<div align=center>
<img src="https://i.imgur.com/ntBdQI7.png" width="80%">
</div>

在内积的基础上就可以定义长度、角度等几何量。

<div align=center>
<img src="https://i.imgur.com/CyLOXNE.png" width="80%">
</div>

实际上很多几何处理任务都隐含了黎曼流形的假设。

<div align=center>
<img src="https://i.imgur.com/vOrhcLa.png" width="80%">
<img src="https://i.imgur.com/dzKl0bq.png" width="80%">
</div>

### Riemannian Gradient

在黎曼流形上我们可以定义**黎曼梯度(Riemannian gradient)**。和欧式空间中的梯度相比，黎曼梯度需要结合流形上的度量张量。

<div align=center>
<img src="https://i.imgur.com/iQ0z0zz.png" width="80%">
</div>

更具体来说，假设流形$\mathcal{M}$上$\mathbf{p}$点附近存在局部参数化$\Phi: \mathbb{R}^n \rightarrow \mathcal{M}$，我们定义参数域上的内积为向量映射到$\mathcal{M}$切平面上的内积：

$$
g_{\mathbf{x}}(\mathbf{v}, \mathbf{w}) = d \Phi_\mathbf{x} (\mathbf{v}) \cdot d \Phi_\mathbf{x} (\mathbf{w})
$$

进一步取$\mathbf{v}$和$\mathbf{w}$为参数域上的基向量，则内积可以表示为一个(半正定)矩阵$g_{ij}$：

$$
g_{ij} (\mathbf{x}) = g_{\mathbf{x}}(\mathbf{e}_i, \mathbf{e}_j)
$$

<div align=center>
<img src="https://i.imgur.com/xZtB1ko.png" width="80%">
</div>

更进一步可以证明流形$\mathcal{M}$上的梯度依赖于参数域$\mathbb{R}^n$上的内积定义：

$$
\nabla_{\mathcal{M}} f = g^{-1} \nabla_{\mathbb{R}^n} f
$$

<div align=center>
<img src="https://i.imgur.com/uVvEjgK.png" width="80%">
</div>

结合上面的推导可以得到**黎曼梯度下降(Riemannian gradient descent)**算法，我们只需要把欧式空间中的梯度替换为黎曼梯度并且把沿梯度下降换成指数映射即可。

<div align=center>
<img src="https://i.imgur.com/BxSaxqv.png" width="80%">
</div>

### Extensions

对于**线搜索(line search)**这样的技术也可以进行类似的推广。

<div align=center>
<img src="https://i.imgur.com/UIph04M.png" width="80%">
</div>

我们还可以把牛顿法这样的二阶方法也推广到黎曼流形上，不过这需要在黎曼流形上定义Hessian矩阵。

<div align=center>
<img src="https://i.imgur.com/lA6QlLT.png" width="80%">
</div>

我们甚至可以在黎曼流形上重新定义凸性。

<div align=center>
<img src="https://i.imgur.com/divomAo.png" width="80%">
</div>

### Example: Unit Sphere

接下来我们以$\mathbb{R}^n$上的单位球为例推导流形上的优化算法。显然此时的优化变量$\mathbf{x}$位于$n-1$维的流形上。

<div align=center>
<img src="https://i.imgur.com/D0mv3va.png" width="80%">
</div>

在$\mathbf{p} \in S^{n-1}$点上法向量由坐标直接给出，因此$\mathbf{p}$点的切空间可以表示为所有与法向量$\mathbf{p}$正交的向量集合：

$$
T_\mathbf{p} S^{n-1} = \{ \mathbf{v} \in \mathbb{R}^n | \mathbf{v} \cdot \mathbf{p} = 0 \}
$$

<div align=center>
<img src="https://i.imgur.com/4AYVeVp.png" width="80%">
</div>

对于$\mathbb{R}^n$上的函数$f$，我们需要把梯度投影到流形上：

$$
\nabla_{S^{n-1}} f (\mathbf{p}) = (I_{n \times n} - \mathbf{p} \mathbf{p}^T) \nabla_{\mathbb{R}^{n}} f (\mathbf{p})
$$

<div align=center>
<img src="https://i.imgur.com/qwm34Oo.png" width="80%">
</div>

接下来我们设计retraction，在单位球上可以使用指数映射的解析形式或是先在切空间上进行移动再投影到流形上。当移动的步长比较小时，两种方法的结果是非常近似的。

<div align=center>
<img src="https://i.imgur.com/pNibpVu.png" width="80%">
</div>

### Example: Stiefel Manifold



<div align=center>
<img src="https://i.imgur.com/2uQEkPs.png" width="80%">
</div>


## Reference

- [Lecture 18: Optimization on manifolds; retractions](https://www.youtube.com/watch?v=2mnqWES2roQ&list=PLQ3UicqQtfNtUcdTMLgKSTTOiEsCw2VBW&index=25)
- [Lecture 18 (extra content): Manifold optimization for PCA problems](https://www.youtube.com/watch?v=hiqIj5jJdbk&list=PLQ3UicqQtfNtUcdTMLgKSTTOiEsCw2VBW&index=26)
- [Optimization on Manifolds](https://groups.csail.mit.edu/gdpgroup/assets/6838_spring_2021/12_manifold_optimization.pdf)