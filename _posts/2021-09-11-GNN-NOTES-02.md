---
layout: article
title: 深蓝学院-GNN课程笔记02-深度学习基础
tags: ["深蓝学院", "GNN"]
key: 深蓝学院-GNN-02
aside:
  toc: true
sidebar:
  nav: GNN
---

> 这个系列是深蓝学院[图深度学习理论与实践](https://www.shenlanxueyuan.com/my/course/376)的同步课程笔记。课程内容涉及图深度学习的基础理论与应用，本节主要介绍深度学习的基础知识。
<!--more-->

## 深度学习简史

所谓深度学习(Deep Learning)是指使用深层的神经网络来解决机器学习的问题，其大致发展脉络如下：

<div align=center>
<img src="https://i.imgur.com/1LDcRqx.png" width="41%">
<img src="https://i.imgur.com/es61qfQ.png" width="40%">
</div>

早在上世纪四十年代研究人员就受到生物神经系统的启发提出了**人工神经元模型(McCulloch-Pitts neuron)**。在五十年代，人工神经网络不断发展并产生了**感知机模型(perceptron)**。到了六十年代，**反向传播(backpropagation)**的思想最早出现在控制理论中，随后由Hinton等拓展到神经网络的训练过程并一直沿用到今天。而在八十年代出现了早期的**卷积神经网络(convolutional neural network, CNN)**和**循环神经网络(recurrent neural network, RNN)**等模型，并在图像识别以及序列数据分析等领域得到了一定的应用。

<div align=center>
<img src="https://cdn-cfofm.nitrocdn.com/MMCsahxLgXapyDWrjVzGzdjiRyqxAjlx/assets/static/optimized/brainmadesimple.com/wp-content/uploads/2019/10/64c6868a7266d557c41b169b041221b1.neuronial-developement.png" width="40%">
<img src="https://i.imgur.com/Nk3pmbN.png" width="40%">
</div>

进入二十一世纪，随着数据量以及计算能力的增长，深度学习取得了爆发性的进步。高速GPU的出现使得训练大规模神经网络模型成为了可能，同时超大规模训练数据库的出现又保证了模型具有足够强的泛化能力。因此深度学习的相关方法在各种各样应用中的表现都远远高于传统的机器学习方法，在不同的研究领域中都取得了巨大的成功和社会影响力。在2012年的ILSVRC图像识别竞赛中，使用深度卷积网络的AlexNet将图像识别的错误率由25.8%降低到了16.4%。随后几年深度卷积网络迅速统治了图像识别领域并成功将图像识别的错误率降低到了3.5%，以及低于人眼的识别错误率。2016年基于**深度强化学习(deep reinforcement learning)**的AlphaGo模型首次在围棋领域击败了人类最强棋手，这一成绩使得人工智能的概念进入到大众视野。到了2018年，基于深度学习的预训练语言模型BERT横空出世并在**自然语言处理(natural language processing, NLP)**的各个领域中都取得了突破性的进步。同年，图灵奖颁发给了Yoshua Bengio，Geoffrey Hinton以及Lann Lecun以表彰他们在深度学习领域做出的奠基性工作。

<div align=center>
<img src="https://i.imgur.com/0Xs0t3M.png" width="70%">
</div>


## 前馈神经网络

## 神经网络的训练

## 卷积神经网络

## 循环神经网络

## 自编码器