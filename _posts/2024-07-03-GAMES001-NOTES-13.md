---
layout: article
title: GAMES001课程笔记13-优化基础
tags: ["CG", "GAMES001", "Math"]
key: GAMES001-13
aside:
  toc: true
sidebar:
  nav: GAMES001
---

> 这个系列是GAMES001-图形学中的数学([GAMES 001: Mathematics in Computer Graphics](https://games-cn.org/games001/))的同步课程笔记。课程旨在总结归纳图形学学习过程中重要的数学概念、理论和方法，并将以索引的形式在每一章节中穿插讲解该数学专题在图形学中的应用。本课程既可以作为GAMES系列其它课程学习的基础或"手册"，也可以作为站在不一样的视角复习图形学知识的平台。本节主要介绍求解数学优化的相关技术。
<!--more-->

数学优化是一个非常广泛且重要的研究领域。从形式上来看，优化问题的目标是最小化一个函数$$f(x)$$。在这个过程中，优化目标函数$$f$$和待优化的变量$$x$$既可以是离散的，也可以是连续的。同时，变量$$x$$还可能需要满足一定的约束条件$$C$$，记为$$x \in C$$。针对不同类型的优化问题，人们设计了各种优化算法来进行求解。

<div align=center>
<img src="https://search.pstatic.net/common?src=https://i.imgur.com/WTs2m5l.png" width="100%">
<img src="https://search.pstatic.net/common?src=https://i.imgur.com/LMxJqSf.png" width="100%">
</div>

## 无约束优化

优化问题中最基础的是无约束优化问题。此时可以令$$C$$为全空间，同时假设$$x \in \mathbb{R}^n$$是连续的向量，且目标函数$$f(x)$$是连续可微的函数。

<div align=center>
<img src="https://search.pstatic.net/common?src=https://i.imgur.com/OQvhH9f.png" width="100%">
</div>

在这样的框架下，许多问题，例如最小二乘法、曲面参数化以及弹性体仿真等，都可以等价地表示为无约束优化问题。

<div align=center>
<img src="https://search.pstatic.net/common?src=https://i.imgur.com/FAA7Ty4.png" width="100%">
<img src="https://search.pstatic.net/common?src=https://i.imgur.com/vlkrNxe.png" width="100%">
<img src="https://search.pstatic.net/common?src=https://i.imgur.com/73enMta.png" width="100%">
<img src="https://search.pstatic.net/common?src=https://i.imgur.com/jyDLEJm.png" width="100%">
</div>

### 线搜索

**线搜索(line search)**是求解无约束优化的一类经典方法，它的基本思想是从当前位置$$x_k$$出发向$$p_k$$方向移动$$\alpha_k$$步长来逐步最小化目标函数。显然，线搜索方法的核心在于如何确定移动方向$$p_k$$以及步长$$\alpha_k$$这两个量。

<div align=center>
<img src="https://search.pstatic.net/common?src=https://i.imgur.com/gW9m06U.png" width="100%">
</div>

#### 梯度下降

**梯度下降(gradient descent)**是线搜索中最常见的一种方法。在梯度下降算法中，我们选择目标函数的负梯度方向作为前进方向，即$$p_k = -\nabla f (x_k)$$。而要确定移动步长$$\alpha_k$$则相对复杂一些，实践中常使用Armijo条件来进行计算。

<div align=center>
<img src="https://search.pstatic.net/common?src=https://i.imgur.com/4JAd48J.png" width="100%">
<img src="https://search.pstatic.net/common?src=https://i.imgur.com/GgE5uGP.png" width="100%">
</div>

结合Armijo条件的梯度下降算法流程可以参考下面ppt。

<div align=center>
<img src="https://search.pstatic.net/common?src=https://i.imgur.com/KFrlfFW.png" width="100%">
</div>

#### 牛顿迭代

梯度下降法只考虑了优化目标函数的一阶信息。为了获得更快的收敛速度，可以结合目标函数的二阶信息，此时得到的算法称为牛顿法。使用牛顿法时，通常要求目标函数在当前位置的Hessian矩阵为正定矩阵。如果Hessian矩阵不是正定的，则需要使用一些额外的方法将其转换为正定矩阵来进行处理。

<div align=center>
<img src="https://search.pstatic.net/common?src=https://i.imgur.com/DJn7sdz.png" width="100%">
<img src="https://search.pstatic.net/common?src=https://i.imgur.com/fr0dSrk.png" width="100%">
</div>

牛顿法的算法流程可以参考下面的ppt。

<div align=center>
<img src="https://search.pstatic.net/common?src=https://i.imgur.com/z82G7YR.png" width="100%">
</div>

与梯度下降法相比，牛顿法通常具有更快的收敛速度，并且可以避免一些震荡的情况。

<div align=center>
<img src="https://search.pstatic.net/common?src=https://i.imgur.com/0nD7vSJ.png" width="100%">
</div>

#### 拟牛顿法

牛顿法的一个缺陷在于每一步迭代中需要计算Hessian矩阵并求解线性方程组来获得前进方向。在某些问题中，这两个步骤可能比较困难且相对耗时。针对这样的问题，我们可以使用一个更容易计算的矩阵$$B_k$$来近似Hessian矩阵，这样的一类方法称为拟牛顿法。

<div align=center>
<img src="https://search.pstatic.net/common?src=https://i.imgur.com/275ibgv.png" width="100%">
</div>

[BFGS算法](https://en.wikipedia.org/wiki/Broyden%E2%80%93Fletcher%E2%80%93Goldfarb%E2%80%93Shanno_algorithm#:~:text=In%20numerical%20optimization%2C%20the%20Broyden,the%20gradient%20with%20curvature%20information.)是目前应用最为广泛的一种拟牛顿法。

<div align=center>
<img src="https://search.pstatic.net/common?src=https://i.imgur.com/DBepGGo.png" width="100%">
<img src="https://search.pstatic.net/common?src=https://i.imgur.com/W2EIa4b.png" width="100%">
<img src="https://search.pstatic.net/common?src=https://i.imgur.com/xc3IEAm.png" width="100%">
<img src="https://search.pstatic.net/common?src=https://i.imgur.com/81RR0W0.png" width="100%">
</div>

BFGS算法的流程可以参考下面的ppt。

<div align=center>
<img src="https://search.pstatic.net/common?src=https://i.imgur.com/JsaYSWP.png" width="100%">
</div>

在BFGS算法的基础上，进一步发展出了[L-BFGS算法](https://en.wikipedia.org/wiki/Limited-memory_BFGS)，旨在降低算法在计算和存储方面的开销。目前，L-BFGS是许多数值计算软件中默认的优化算法。

<div align=center>
<img src="https://search.pstatic.net/common?src=https://i.imgur.com/JoaB4rD.png" width="100%">
</div>

### 不动点迭代

从优化的角度来看，我们之前介绍过的[不动点迭代](/2024/06/21/GAMES001-NOTES-12.html#不动点迭代)实际上也是一种拟牛顿法。

<div align=center>
<img src="https://search.pstatic.net/common?src=https://i.imgur.com/TNSZY3J.png" width="100%">
</div>

## 带约束优化

对于带约束的优化问题，约束可以分为等式约束以及不等式约束两类。

<div align=center>
<img src="https://search.pstatic.net/common?src=https://i.imgur.com/kApbxYK.png" width="100%">
</div>

在物理仿真中的常见约束都可以转换为等式约束以及不等式约束。

<div align=center>
<img src="https://search.pstatic.net/common?src=https://i.imgur.com/COXgyoh.png" width="100%">
</div>

### 等式约束

对于等式约束的情况，我们首先需要考虑在什么情况下目标函数能够达到最优。

<div align=center>
<img src="https://search.pstatic.net/common?src=https://i.imgur.com/B6iWDDi.png" width="100%">
</div>

以二维情况为例，只有在目标函数的梯度$$\nabla f(x, y)$$与约束$$g(x, y)$$的梯度相互平行时能够达到最优，即$$\nabla f = \lambda \nabla g$$。

<div align=center>
<img src="https://search.pstatic.net/common?src=https://i.imgur.com/5buopvh.png" width="100%">
</div>

根据上面的分析可以得到等式约束条件下最优点$$x^*$$需要满足的条件：

$$
g_i(x^*) = 0
$$

$$
\nabla f(x^*) = \sum_i \lambda_i \nabla g_i (x^*)
$$

<div align=center>
<img src="https://search.pstatic.net/common?src=https://i.imgur.com/n5bsPpo.png" width="100%">
</div>

#### 拉格朗日乘子法

更进一步，等式约束条件的最优化问题可以利用[拉格朗日乘子](https://en.wikipedia.org/wiki/Lagrange_multiplier)进行处理。我们定义原始优化问题的拉格朗日函数为

$$
L(x, \lambda_1, ..., \lambda_n) = f(x) - \sum_i \lambda_i g_i (x)
$$

则等式约束的最优解可以表示为

$$
\nabla L = 0
$$

这样约束优化问题就通过拉格朗日乘子转换为了无约束优化问题。然而，需要注意的是仅通过最小化$$L$$并不能保证得到问题的解，还必须确保$$g_i (x) = 0$$始终成立。

<div align=center>
<img src="https://search.pstatic.net/common?src=https://i.imgur.com/0BIa5C9.png" width="100%">
<img src="https://search.pstatic.net/common?src=https://i.imgur.com/8iv1JeF.png" width="100%">
</div>

#### Min-Max问题

实际上，与原始约束优化问题等价的拉格朗日优化问题是一个Min-Max问题：

$$
\min_x \max_{\lambda_i} L(x, \lambda_1, ..., \lambda_n)
$$

<div align=center>
<img src="https://search.pstatic.net/common?src=https://i.imgur.com/TJwiUyJ.png" width="100%">
</div>

对于Min-Max问题，我们无法直接使用前面介绍过的无约束优化方法进行求解。

<div align=center>
<img src="https://search.pstatic.net/common?src=https://i.imgur.com/PdkIdqi.png" width="100%">
<img src="https://search.pstatic.net/common?src=https://i.imgur.com/lkjae3m.png" width="100%">
<img src="https://search.pstatic.net/common?src=https://i.imgur.com/bJSJ9QX.png" width="100%">
</div>

#### 对偶问题

直接求解Min-Max问题往往效率较低。在实践中，通常会将Min-Max问题转换为其对偶问题进行处理。这时需要交换最大化和最小化的顺序，先对$$x$$进行最小化，然后对$$\lambda$$进行最大化，从而将Min-Max问题转化为Max-Min问题。

<div align=center>
<img src="https://search.pstatic.net/common?src=https://i.imgur.com/SkVlcRH.png" width="100%">
</div>

对于一般的函数$$L(x, \lambda)$$，可以证明对偶问题是原始问题的下界，这称为弱对偶关系。而对于凸函数，可以证明原始问题和对偶问题是等价的，称为强对偶条件。

<div align=center>
<img src="https://search.pstatic.net/common?src=https://i.imgur.com/QuC5bIq.png" width="100%">
</div>

假设强对偶条件成立，则可以使用无约束优化问题的相关求解方法进行处理。

<div align=center>
<img src="https://search.pstatic.net/common?src=https://i.imgur.com/Hm9Jswk.png" width="100%">
<img src="https://search.pstatic.net/common?src=https://i.imgur.com/jr8zxod.png" width="100%">
</div>

#### 对偶上升法

对于对偶问题，我们可以使用对偶上升法交替更新$$x$$和$$\lambda$$进行求解。对偶上升法将原始的约束优化问题转换为了两个无约束优化问题，在优化$$\lambda$$时可以利用梯度下降法进行处理。

<div align=center>
<img src="https://search.pstatic.net/common?src=https://i.imgur.com/EelKXj3.png" width="100%">
<img src="https://search.pstatic.net/common?src=https://i.imgur.com/JFo3pwr.png" width="100%">
</div>

#### 罚函数法

除了拉格朗日乘子法之外，对于等式约束的优化问题还可以使用罚函数法。其基本思想是将等式约束视为一个惩罚项，当$$x$$违反约束时施加相应的惩罚来约束$$x$$。然而，罚函数法无法保证约束一定能够严格满足，只能保证近似满足。实践中一般需要调节惩罚项系数$$\mu$$来保证优化能够收敛。

<div align=center>
<img src="https://search.pstatic.net/common?src=https://i.imgur.com/aBswLUb.png" width="100%">
</div>

### 不等式约束

## Reference

- [Lecture 14: 优化基础](https://www.bilibili.com/video/BV1MF4m1V7e3?p=15&vd_source=7a2542c6c909b3ee1fab551277360826)