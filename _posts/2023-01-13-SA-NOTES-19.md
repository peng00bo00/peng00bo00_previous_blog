---
layout: article
title: Shape Analysis课程笔记19-Clustering and Segmentation
tags: ["CG", "Geometry Processing", "Shape Analysis"]
key: SA-17
aside:
  toc: true
sidebar:
  nav: SA
---

> 这个系列是[MIT 6.838: Shape Analysis](https://groups.csail.mit.edu/gdpgroup/6838_spring_2021.html)的同步课程笔记。本课程会介绍几何方法在图形学、机器学习、计算机视觉、医疗图像以及建筑设计等相关领域的原理和应用。本节主要介绍聚类和分割问题。
<!--more-->

## Clustering and Segmentation

**聚类(clustering)**是机器学习中的经典问题，而在CV和几何处理中聚类问题也可以理解为是**分割(segmentation)**。

<div align=center>
<img src="https://i.imgur.com/BKYSc6q.png" width="80%">
</div>

本节课中我们会关注几何视角下的聚类问题，同时也会基于几何的视角来对它进行处理。

<div align=center>
<img src="https://i.imgur.com/WpnLoPt.png" width="80%">
</div>

### Applications

除了无监督学习外，聚类在CAD、医学成像以及CG中都有着广泛的应用。

<div align=center>
<img src="https://i.imgur.com/X66OS8R.png" width="80%">
</div>

然而在处理聚类问题时的难点在于如何去定义一个好的分割。很多时候这个定义是非常模糊的，因此我们一般会结合实际的任务需求来进行考虑。

<div align=center>
<img src="https://i.imgur.com/uE8UXky.png" width="80%">
</div>

## Semantic Segmentation

**语义分割(semantic segmentation)**是CV中的经典问题。在语义分割中我们希望能够对图片上每个像素的类别进行标记，从而得到有意义的分割。

<div align=center>
<img src="https://i.imgur.com/26dbZK5.png" width="80%">
<img src="https://i.imgur.com/i7ZuYoW.png" width="80%">
</div>

尽管在今天语义分割已经有很多很成熟的处理方法，本节课我们会介绍一些基于几何的算法。

<div align=center>
<img src="https://i.imgur.com/db4QbYY.png" width="80%">
</div>

### k-Means

**k-means**是最基本的聚类算法。从几何的角度来看，k-means等价于寻找数据集上的k个聚类中心使得每个数据点$\mathbf{x}$到最近中心的距离之和最小。可以证明所需的聚类中心恰好为该类数据点的几何中心。

<div align=center>
<img src="https://i.imgur.com/l8MBHiX.png" width="80%">
</div>

k-means算法的难点在于如何去初始化这些聚类中心。而当聚类中心确定后我们只需要把每个样本标记到最近的中心，然后更新聚类中心的坐标即可。从几何的角度来看，这一过程等价于构造**Voronoi图(Voronoi diagram)**，即k-means算法可以理解为使用Voronoi图对空间进行划分。

<div align=center>
<img src="https://i.imgur.com/zsfbNNO.png" width="80%">
<img src="https://i.imgur.com/WJ7pmYY.png" width="80%">
</div>

### k-Means++

k-means算法的一个缺陷在于它高度依赖于初始化聚类中心的选择。k-means++算法中使用样本到最近中心的距离平方作为概率密度函数，然后通过抽样来初始化聚类中心。

<div align=center>
<img src="https://i.imgur.com/qKZRZLB.png" width="80%">
</div>

k-means++的基础上很多现代方法提出了更好的初始化和抽样策略。

<div align=center>
<img src="https://i.imgur.com/xnJocFE.png" width="80%">
</div>

### The Gap Statistic

k-means算法的另一个难点在于如何选取距离中心的数量k。除了根据实际需求进行设置外也可以利用**gap statistic**这样的技术来自动计算。

<div align=center>
<img src="https://i.imgur.com/7fwMrjW.png" width="80%">
</div>

### k-Means Applications

尽管k-means算法非常简单，但在工程中有着非常广泛的应用。比如说基于k-means进行颜色聚类或是对网格进行分割。

<div align=center>
<img src="https://i.imgur.com/OsUeoUe.png" width="80%">
<img src="https://i.imgur.com/LozCRtg.png" width="80%">
</div>

当然k-means算法的随机性也往往会对聚类结果产生扰动，很难说这是算法的bug还是它的特性。

<div align=center>
<img src="https://i.imgur.com/Nzl4ZRg.png" width="80%">
<img src="https://i.imgur.com/7QEojCk.png" width="80%">
</div>

### Semidiscrete Transport

从最优运输的角度来考虑，k-means还可以理解成[半离散运输](/2023/01/12/SA-NOTES-18.html#semidiscrete-transport)。实际上通过设计不同的权重，我们可以推导出不同的k-means算法。

<div align=center>
<img src="https://i.imgur.com/9cUVqSP.png" width="80%">
<img src="https://i.imgur.com/tVmRrlP.png" width="80%">
<img src="https://i.imgur.com/g7UpQvQ.png" width="80%">
</div>

如此定义最优运输问题后，就可以使用一些标准的解法进行处理。

<div align=center>
<img src="https://i.imgur.com/CLYlXb7.png" width="80%">
</div>

<div align=center>
<img src="https://i.imgur.com/MSwG12X.png" width="80%">
</div>

### Geometry of k-Means

到目前位置我们都假定了k-means算法的样本都分布在欧式空间中，而当样本不满足这样的假定时k-means的效果就会非常差。因此我们需要对k-means进行推广，使得它能够处理更一般的问题。

<div align=center>
<img src="https://i.imgur.com/f5WJb69.png" width="80%">
<img src="https://i.imgur.com/N76g0QB.png" width="80%">
</div>

对于如何定义样本的均值的问题，这里可以使用Fréchet mean来对欧式空间中的均值进行推广。可以证明在欧式空间中Fréchet mean与我们通常意义下的均值是相同的。

<div align=center>
<img src="https://i.imgur.com/Vha6wWK.png" width="80%">
</div>

而在更一般的度量空间中，Fréchet mean会具有一些几何上的意义。

<div align=center>
<img src="https://i.imgur.com/KrgsOWt.png" width="80%">
<img src="https://i.imgur.com/QyukWlG.png" width="80%">
</div>

Fréchet mean甚至对如何训练神经网络也有一定的启发。

<div align=center>
<img src="https://i.imgur.com/Fkaypqh.png" width="80%">
</div>

## Reference

- [Lecture 20: Segmentation and clustering (k-means, Frechet means, normalized cuts)](https://www.youtube.com/watch?v=JuS_brnMpnE&list=PLQ3UicqQtfNtUcdTMLgKSTTOiEsCw2VBW&index=28)
- [Clustering and Segmentation](https://groups.csail.mit.edu/gdpgroup/assets/6838_spring_2021/14_clustering_segmentation.pdf)