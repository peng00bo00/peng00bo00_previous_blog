---
layout: article
title: 深蓝学院-GNN课程笔记08-自然语言处理中的图神经网络
tags: ["深蓝学院", "GNN"]
key: 深蓝学院-GNN-08
aside:
  toc: true
sidebar:
  nav: GNN
---

> 这个系列是深蓝学院[图深度学习理论与实践](https://www.shenlanxueyuan.com/course/376?source=1)的同步课程笔记。课程内容涉及图深度学习的基础理论与应用，本节主要介绍图神经网络在自然语言处理中的应用。
<!--more-->

在**自然语言处理(natural language processing)**中存在着大量的图结构，因此我们可以把图神经网络应用在自然语言处理中或者使用图神经网络来提升现有方法的性能。

## 语义角色标注

**语义角色标注(semantic role labeling, SRL)**的目的是发现句子中的**谓语-论元(predicate-argument)**结构，简单来理解就是去发现"谁在哪里做了什么"。SRL在问答系统、信息检索和机器翻译中都有大量的应用。

<div align=center>
<img src="https://pic1.xuehuaimg.com/proxy/i.imgur.com/XUjtmxt.png" width="70%">
</div>

SRL的基本步骤包括检测谓语、识别论元以及标注论元三个步骤。从标注结果来看SRL可以理解为一个序列标注任务，我们需要标注给定谓词的所有论元，并将所有非论元标注为`NULL`。

<div align=center>
<img src="https://pic1.xuehuaimg.com/proxy/i.imgur.com/3eEw7Xr.png" width="70%">
</div>

SRL的基本方法是使用Bi-LSTM来捕获上下文信息并计算序列中每个词的嵌入，然后将它们拼接起来并训练一个分类器来获得最终的标注。

<div align=center>
<img src="https://pic1.xuehuaimg.com/proxy/i.imgur.com/cTmrdE9.png" width="70%">
</div>

在此基础上我们可以利用**依存句法树(syntactic dependency tree)**和图神经网络来提升提升标注的效果。依存句法树描述了单词之间在语法上的依赖关系，句子中每个单词都是树的节点，根据单词之间的依赖关系存在不同类型的边。同时不难发现依存句法树与语义关系之间有很多的相似之处：

<div align=center>
<img src="https://pic1.xuehuaimg.com/proxy/i.imgur.com/EMgAHus.png" width="70%">
</div>

在依存句法树的基础上我们就可以使用GNN来融合语法和语义信息并提升SRL的性能。需要注意的是依存句法树中的边是有向边，而且针对不同类型的边需要使用不同的系数矩阵。

<div align=center>
<img src="https://pic1.xuehuaimg.com/proxy/i.imgur.com/ksLYM5X.png" width="70%">
</div>

## 神经机器翻译

机器翻译是NLP的基本任务之一。目前随着深度学习的发展，机器翻译的主流方法都是基于神经网络建模：输入句子通过一个神经网络编码器得到隐状态，然后再通过一个解码器来获得翻译后的句子。

<div align=center>
<img src="https://pic1.xuehuaimg.com/proxy/i.imgur.com/8TxAjYY.png" width="70%">
</div>

编码器和解码器通常使用RNN及其变体来进行建模。类似于SRL，我们可以使用一个Bi-LSTM来获得输入句子中每个词的嵌入并利用注意力机制来计算隐状态，最后再使用解码器来输出翻译后的句子。

<div align=center>
<img src="https://pic1.xuehuaimg.com/proxy/i.imgur.com/K4U7Sn0.png" width="70%">
</div>

我们同样可以使用GNN来提升机器翻译的性能，在Bi-LSTM后面使用依存句法树和GNN来获得整个句子的表示。最后，把GNN的输出作为解码器的输入。

<div align=center>
<img src="https://pic1.xuehuaimg.com/proxy/i.imgur.com/eKMIIpS.png" width="70%">
</div>

## 关系抽取

**关系抽取(relation extraction)**的目的是预测句子中两个实体是否存在关系，显然它也是一个分类任务。

<div align=center>
<img src="https://pic1.xuehuaimg.com/proxy/i.imgur.com/5fAaIpk.png" width="40%">
</div>

类似于前面介绍过的内容，我们同样可以使用GNN来进行关系抽取。首先使用Bi-LSTM来计算每个词的嵌入，然后利用依存句法树和GNN来融合语法信息得到更新后的词嵌入。最后进行分类时则将整个句子的表示以及两个实体的表示拼接到一起作为分类器的输入。

<div align=center>
<img src="https://pic1.xuehuaimg.com/proxy/i.imgur.com/4g536Fz.png" width="70%">
</div>

## 多跳问答任务

**问答(QA)**是NLP中富有挑战性的一项任务，我们希望模型能够通过理解文档来生成给定问题的答案。通常情况下为了回答问题可能需要查询多个文档，因此我们需要构造问题的同一实体在不同文档中的关系图，并在这张图上进行信息传播来生成答案。

<div align=center>
<img src="https://pic1.xuehuaimg.com/proxy/i.imgur.com/1VAVIvM.png" width="70%">
</div>

为了构造关系图我们需要考虑问题实体在不同文档中提及的形式，基本的形式包括`MATCH`、`DOC-BASED`、`COREF`、`COMPLEMENT`几种：如果两个提及(文档内或文档间)相同则使用`MATCH`将它们进行连接；如果两个提及出现在同一个文档中则使用`DOC-BASED`进行连接；如果两个提及指向同一个内容则使用`COREF`进行连接；最后为了避免出现不连通的子图还需要在所有不相连的节点之间加入`COMPLEMENT`边，这样整个图就构成了一个全连接图。

<div align=center>
<img src="https://pic1.xuehuaimg.com/proxy/i.imgur.com/WZTfOdm.png" width="70%">
</div>

获得图结构后就可以使用GNN来学习节点表示并进行推理。进行信息聚合时需要注意不同类型的边需要使用不同的系数矩阵，同时信息更新时也可以使用不同的更新机制。

<div align=center>
<img src="https://pic1.xuehuaimg.com/proxy/i.imgur.com/116agec.png" width="70%">
</div>

## 知识图谱中的神经网络

**知识图谱(knowledge graph)**是图神经网络的重要应用。一般来说知识图谱中包含不同类型的实体(节点)和关系(边)，而GNN可以拓展到知识图谱中用以学习节点表示并辅助各种下游任务。使用GNN处理知识图谱时主要包括两种做法：

1. 将不同类型的边融入图滤波器中；
2. 将知识图谱转换为一个简单无向图，然后使用通常的GNN进行处理。

<div align=center>
<img src="https://pic1.xuehuaimg.com/proxy/i.imgur.com/90Zpam9.png" width="70%">
</div>

针对知识图谱的图滤波器有很多类型，最基础的是在信息聚合时为每一种类型的边指定一个系数矩阵，需要注意的是当图上具有大量的不同类型的边时这种方法需要的参数量非常巨大。而在CompGCN中则考虑正向、反向以及self-loop三个方向，每种类型的边使用一个矩阵$Z$来描述。

<div align=center>
<img src="https://pic1.xuehuaimg.com/proxy/i.imgur.com/PQNQ17N.png" width="70%">
</div>

如果要将知识图谱转换为一个简单图则需要修改图的邻接矩阵。具体地，我们可以通过不同类型边的分数来描述两个节点之间的关系，然后把这个分数作为简单图的邻接矩阵：

<div align=center>
<img src="https://pic1.xuehuaimg.com/proxy/i.imgur.com/Q4GLXZg.png" width="70%">
</div>