---
layout: article
title: PBRT读书笔记10-Monte Carlo Integration
tags: ["PBRT", "Rendering", "CG"]
key: PBRT-10
aside:
  toc: true
sidebar:
  nav: PBRT
---

> 这个系列是[Physically Based Rendering: From Theory To Implementation](https://pbr-book.org/)的读书笔记，本节主要介绍Monte Carlo积分的相关知识。
<!--more-->

在渲染过程中我们经常需要去计算各种各样的高维数值积分。这些被积函数往往十分复杂，甚至没有解析形式。计算这类函数的积分一般需要在被积范围内进行采样，因此这种方法称为**Monte Carlo积分(Monte Carlo integration)**。

## Background and Probability Review

在正式介绍Monte Carlo积分前首先简要复习一下概率论和随机变量的相关知识。对于随机变量我们使用斜体$X$来表示，把某个函数$f$作用在$X$上时我们会得到一个新的随机变量$Y = f(X)$。离散型随机变量的**累计概率分布函数(cumulative distribution function, CDF)**定义为：

$$
P(x) = Pr(X \leq x)
$$

### Continuous Random Variables

在渲染中更为常用的是连续型随机变量，其中[0, 1)区间上均匀分布的随机变量记为$\xi$。$\xi$是一个非常重要的随机变量，利用$\xi$可以生成更加复杂分布的随机变量。我们定义连续型随机变量的**概率密度函数(probability density function, PDF)**为CDF的微分：

$$
p(x) = \frac{d \ P(x)}{d \ x}
$$

对于均匀分布的随机变量$\xi$，它的PDF为

$$
p(x) = 
\left\{
\begin{aligned}
& 1 & & x \in [0, 1) \\
& 0 & & \text{otherwise}
\end{aligned}
\right.
$$

需要注意的是任意PDF必须满足非负而且积分为1。在给定区间[a, b]上PDF的积分即为随机变量落在该范围上的概率：

$$
P(x \in [a, b]) = \int_a^b p(x) \ dx
$$

### Expected Values and Variance

我们定义函数$f$在给定概率分布$p(x)$上的**期望(expected value)**为$f(x)$与$p(x)$的积分：

$$
E_p [f(x)] = \int_D f(x) p(x) \ dx
$$

定义$f$的**方差(variance)**为$f(x)$偏离自身期望的程度：

$$
V[f(x)] = E \bigg[ \big( f(x) - E[f(x)] \big)^2 \bigg] = E[(f(x))^2] - E[f(x)]^2
$$

期望和方差的常用性质如下：

$$
E[a f(x)] = a E[f(x)]
$$

$$
E\bigg[ \sum_i f(x_i) \bigg] = \sum_i E[f(x_i)]
$$

$$
V[a f(x)] = a^2 V[f(x)]
$$

对于相互独立的随机变量，它们的方差具有可加性：

$$
\sum_i V[f(x_i)] = V \bigg[ \sum_i f(x_i) \bigg]
$$

## The Monte Carlo Estimator

对于一元函数$f(x)$，它在[a, b]上的积分$\int_a^b f(x) dx$可以通过[a, b]上均匀分布随机变量$X_i$的函数来估计：

$$
F_N = \frac{b-a}{N} \sum_{i=1}^N f(X_i)
$$

实际上$F_N$的期望恰好等于积分：

$$
\begin{aligned}
E[F_N] &= E \bigg[ \frac{b-a}{N} \sum_{i=1}^N f(X_i) \bigg] \\
&= \frac{b-a}{N} \sum_{i=1}^N E[f(X_i)] \\
&= \frac{b-a}{N} \sum_{i=1}^N \int_a^b f(x) p(x) \ dx \\
&= \frac{1}{N} \sum_{i=1}^N \int_a^b f(x) \ dx \\
&= \int_a^b f(x) \ dx
\end{aligned}
$$

实际上我们并不需要将随机变量限制为均匀分布，对于任意分布$p(x)$只需要对估计进行一定的变形：

$$
F_N = \frac{1}{N} \sum_{i=1}^N \frac{f(X_i)}{p(X_i)}
$$

同样可以证明上式的期望等于积分值：

$$
\begin{aligned}
E[F_N] &= E \bigg[ \frac{1}{N} \sum_{i=1}^N \frac{f(X_i)}{p(X_i)} \bigg] \\
&= \frac{1}{N} \sum_{i=1}^N \int_a^b \frac{f(x)}{p(x)} p(x) \ dx \\
&= \frac{1}{N} \sum_{i=1}^N \int_a^b f(x) \ dx \\
&= \int_a^b f(x) \ dx
\end{aligned}
$$

Monte Carlo积分同样可以拓展到多元函数上。假设我们想要计算一个三重积分：

$$
\int_{z_0}^{z_1} \int_{y_0}^{y_1} \int_{x_0}^{x_1} f(x, y, z) \ dx \ dy \ dz
$$

为了计算积分值需要从$[x_0, x_1] \times [y_0, y_1] \times [z_0, z_1]$进行均匀采样，每个样本的PDF均为：

$$
\frac{1}{x_1 - x_0} \cdot \frac{1}{y_1 - y_0} \cdot \frac{1}{z_1 - z_0}
$$

因此使用Monte Carlo积分得到的估计值为：

$$
\frac{(x_1 - x_0)(y_1 - y_0)(z_1 - z_0)}{N} \sum_i f(X_i)
$$

对于Monte Carlo积分而言样本数$N$可以是任意的。这样的好处在于无论被积函数的维度如何我们都可以很好地控制计算复杂度，这也是Monte Carlo积分优于很多其它数值积分方法的原因之一。

除此之外还需要考虑的是Monte Carlo积分的精度，实际上可以证明Monte Carlo积分误差的收敛速度为$O(\sqrt{N})$且与维数无关。对于一维的情况很多数值积分方法都有着更好的收敛速度，但随着维数的增加这些数值积分的精度会显著下降。因此在多维的情况下Monte Carlo积分几乎是唯一可行的积分方法。

## Sampling Random Variables

Monte Carlo积分的难点在于如何对各种不同类型的分布进行采样，在本节中我们暂时只介绍最简单的两种采样方法，更多复杂的采样方法会留到后面的章节再进行介绍。

### The Inversion Method

最基本的采样方法是**逆变换采样(inverse transform sampling)**。对于任意分布的随机变量$X$可以证明把CDF作用到$X$上后会得到均匀分布，即$P(X) \sim U(0, 1)$。因此我们只需要从均匀分布进行采样，然后利用$P(x)$的反函数即可获得来自$X$分布的样本。

<div align=center>
<img src="https://pbr-book.org/3ed-2018/Monte_Carlo_Integration/discrete-cdf.svg" width="40%">
<img src="https://pbr-book.org/3ed-2018/Monte_Carlo_Integration/discrete-inversion.svg" width="40%">
</div>

逆变换采样的步骤如下：

- 计算随机变量$X$的CDF：$$P(x) = \int_0^x p(x') \ dx'$$
- 计算CDF的反函数$P^{-1}(x)$
- 从均匀分布$U(0, 1)$进行采样，得到样本$\xi$
- 利用CDF的反函数得到来自$X$分布的样本$X_i = P^{-1}(\xi)$

#### Power Distribution

对于**幂分布(power distribution)**，它的PDF可以表示为：

$$
p(x) = c x^n
$$

利用PDF的归一化条件可以求得常数$c$为：

$$
\int_0^1 c x^n \ dx = 1 \ \Leftrightarrow \ c = n+1
$$

因此幂分布的CDF为：

$$
P(x) = \int_0^x p(x') \ dx' = x^{n+1}
$$

对应的反函数为：

$$
P^{-1} (x) = \sqrt[n+1]{x}
$$

因此要获得幂分布的样本只需要对均匀分布的样本$\xi$进行逆变换即可：

$$
X = \sqrt[n+1]{\xi}
$$

#### Exponential Distribution

对于参数为$a$的指数分布，其CDF为：

$$
P(x) = \int_0^x a e^{-ax'} \ dx' = 1 - e^{-a x}
$$

对应的反函数为：

$$
P^{-1} (x) = -\frac{\ln(1-x)}{a}
$$

因此获取指数分布的样本只需要利用变换：

$$
X = -\frac{\ln(1-\xi)}{a}
$$

#### Piecewise-Constant 1D Functions

很多时候我们需要考虑分段的概率分布。假设每一段的大小是均匀的$\Delta = \frac{1}{N}$，此时未归一化的PDF可以表示为：

$$
f(x) = 
\left\{
\begin{aligned}
& v_0 & & x_0 \leq x \lt x_1 \\
& v_1 & & x_1 \leq x \lt x_2 \\
& \vdots
\end{aligned}
\right.
$$

利用PDF的归一化条件可以得到归一化常数$c$：

$$
c = \int_0^1 f(x) \ dx = \sum_{i=0}^{N-1} v_i \Delta = \sum_{i=0}^{N-1} \frac{v_i}{N}
$$

因此CDF在不同间隔上的值为：

$$
P(x_0) = 0
$$

$$
P(x_1) = P(x_0) + \frac{v_0}{c N}
$$

$$
P(x_2) = P(x_1) + \frac{v_1}{c N}
$$

$$
P(x_i) = P(x_{i-1}) + \frac{v_{i-1}}{c N}
$$

<div align=center>
<img src="https://pbr-book.org/3ed-2018/Monte_Carlo_Integration/constant-func-pdf.svg" width="40%">
<img src="https://pbr-book.org/3ed-2018/Monte_Carlo_Integration/constant-func-cdf.svg" width="40%">
</div>

进行逆变换采样时需要计算$\xi$位于的区间使得$P(x_i) \leq \xi$且$\xi \leq P(x_{i+1})$。在已知CDF的情况下可以使用二分查找的方法来加速计算过程。

### The Rejection Method

对于某些分布的CDF直接进行计算可能非常复杂甚至没有解析形式，此时就不能使用逆变换采样。在这种情况下可以使用**接受-拒绝采样(acceptance-rejection sampling)**来生成样本。接受-拒绝采样不需要计算概率分布的CDF，只需要目标分布$f(x)$和另一个已知分布$p(x)$的PDF即可，同时两个分布的PDF需要满足$f(x) \leq c p(x)$，其中$c$为常数。

接受-拒绝采样的步骤如下：

- 从已知分布$p(x)$上生成样本$X$
- 从均匀分布$U(0, 1)$上采样一个随机数$\xi$
- 如果$\xi \leq \frac{f(X)}{c p(X)}$则接受$X$作为样本，否则回到第一步重新进行采样

从几何意义上讲接受-拒绝采样会生成随机变量对$(X, \xi)$，如果点$(X, \xi \cdot c p(X))$位于曲线$f(X)$的下方则接受样本。接受-拒绝采样的一个优势在于它与随机变量的维数无关，只要能够计算PDF即可。

<div align=center>
<img src="https://pbr-book.org/3ed-2018/Monte_Carlo_Integration/rejection-sample-func.svg" width="50%">
</div>

#### Rejection Sampling a Unit Circle

接受-拒绝采样的经典应用是生成圆内均匀分布的样本。我们只需要在正方形区域内进行均匀采样，然后拒绝掉落在圆外的样本即可。

<div align=center>
<img src="https://pbr-book.org/3ed-2018/Monte_Carlo_Integration/rejection-sample-circle.svg" width="30%">
</div>

在PBRT中使用`RejectionSampleDisk()`函数来描述单位圆内进行均匀采样的过程：

```cpp
Point2f RejectionSampleDisk(RNG &rng) {
    Point2f p;
    do {
        p.x = 1 - 2 * rng.UniformFloat();
        p.y = 1 - 2 * rng.UniformFloat();
    } while (p.x * p.x + p.y * p.y > 1);
    return p;
}
```

## Metropolis Sampling

**Metropolis采样(Metropolis sampling)**是一种针对非负函数$f(x)$进行采样的方法，其中可以认为$f(x)$是归一化前的概率密度。和前面介绍过的采样方法相比，Metropolis采样不需要积分也不需要计算函数的反函数，只要能对$f(x)$求值即可。而且Metropolis采样不会拒绝生成的样本，在每一轮的采样过程中都可以得到新的数据。因此Metropolis采样比前面介绍过的采样方法都要高效。

Metropolis采样的缺陷在于它是一个迭代的算法，换句话说连续的样本之间是存在一定关联的。它的另一个缺陷在于当采样数比较少时生成的样本可能无法覆盖整个定义域，因此很多降低方差的技术不能直接用在Metropolis采样中。

### Basic Algorithm

Metropolis采样的目标是从给定的函数$f: \Omega \rightarrow \mathbb{R}$上采样出一系列样本$X_i$。设初始的样本为$X_0$，在每一轮采样过程中样本$X_i$都是由前一个样本$X_{i-1}$经过一个随机**突变(mutation)**来获得，突变的结果记为$X'$。我们可以接受或拒绝突变的样本，因此$X_i$的取值为$X_{i-1}$或$X'$。在这种采样模式下$X_i$会达到一种平衡态分布，这个概率分布称为**平稳分布(stationary distribution)**。在极限情况下$X_i$的概率分布即为$f(x)$定义的概率分布：$$p(x) = \frac{f(x)}{\int_\Omega f(x) \ d\Omega}$$。

显然Metropolis采样的核心是设计突变函数以及接受突变的策略。突变函数可以有不同的形式，比如说对当前样本$X$进行扰动或是直接生成一个新的样本都可以。假设我们已经有了某种突变策略，接下来需要考虑从$X$突变为$X'$的概率$T(X \rightarrow X') = P(X' \vert X)$，称为**状态转移函数(transition function)**。在此基础上我们可以定义一个接受概率$a(X \rightarrow X')$表示我们是否要接受突变的样本，从而保证样本$X$的分布正比于$f(x)$。当系统达到平衡态时任意两个状态相互转换的概率必须相等，即：

$$
f(X) \ T(X \rightarrow X') \ a(X \rightarrow X') = f(X') \ T(X' \rightarrow X) \ a(X' \rightarrow X)
$$

上式称为**细致平衡条件(detailed balance)**。当$f$和$T$确定时我们可以得到接受概率$a$的表达式：

$$
a(X \rightarrow X') = \min \bigg( 1, \frac{f(X') \ T(X' \rightarrow X)}{f(X) \ T(X \rightarrow X')} \bigg)
$$

容易验证上式定义的接受概率$a$满足细致平衡条件。如果进一步假设$X$和$X'$相互突变的概率是相等的，则可以得到更简单的接受概率：

$$
a(X \rightarrow X') = \min \bigg( 1, \frac{f(X')}{f(X)} \bigg)
$$

这样我们就得到了最基本的Metropolis采样算法，它的伪代码形式如下：

```
X = X0
for i = 1 to n
    X' = mutate(X)
    a = accept(X, X')
    if (random() < a)
        X = X'
    record(X)
```

当$f(X')$的值比较小时Metropolis采样会有很大的概率拒绝突变，这会使得只有很少的样本会分布在函数值比较小的区域。为了克服这个问题我们可以使用求期望的方法来改进标准的Metropolis采样算法。此时在每一轮采样中需要同时记录$X$和$X'$，并且为它们赋予相应的概率(权重)。改进后的Metropolis采样算法伪代码如下：

```
X = X0
for i = 1 to n
    X' = mutate(X)
    a = accept(X, X')
    record(X, 1 - a)
    record(X', a)
    if (random() < a)
        X = X'
```

### Choosing Mutation Strategies

只要能够计算转移概率$T(X \rightarrow X')$，理论上突变函数可以是任意的。实际应用中为了化简Metropolis采样的过程一般会要求$X$与$X'$之间相互突变的概率是相同，在这个前提下人们总结出了许多常用的突变策略。

一般来说我们希望突变后的样本能够迅速转移到函数值较大的区域而不是停留在函数值较小的区域，但是当$f(X)$很大时Metropolis采样会以很小的概率转移到突变后的样本。我们希望能够避免这种情况，并且使样本尽可能分散在整个定义域上。因此一种突变方法是对$X$进行随机扰动：假设$X$是一个向量且第$i$维是$x_i$，我们通过对$x_i$加减一个随机值实现扰动：

$$
x_i' = (x_i \pm s \ \xi) \% 1
$$

其中$s$表示扰动的尺度；对扰动结果取余数用来进行归一化。显然这种扰动方法满足对称性$T(X \rightarrow X') = T(X' \rightarrow X)$。

一种类似的突变方法是直接使用随机数来代替$x_i'$：

$$
x_i' = \xi
$$

这种突变方式同样是对称的，而且它还可以保证样本在突变过程中能够覆盖到整个定义域而不会局限在某些区域上。

除此之外我们还可以利用已知的PDF来进行突变。假设已知一个概率分布$p(x)$，我们可以直接从遮盖概率分布中进行采样作为突变后的样本。此时转移概率可以表示为：

$$
T(X \rightarrow X') = p(X')
$$

此时突变的结果与当前状态$X$无关。

### Start-up Bias

在Metropolis采样中还需要注意初值$X_0$的选取，如果$X_0$选择的不好会导致一些**初值误差(start-up bias)**。要解决这个问题一种常用的做法是从一个随机初值开始进行采样，抛弃刚开始生成的样本然后把当前状态作为初值重新进行采样。这种做法的缺陷在于抛弃刚开始产生的样本会浪费计算资源，同时我们无法得知要进行多少次迭代才能开始真正的采样。

因此实践中更常用的方式是首先从另一个分布$p(x)$中采样得到初值$X_0$，然后从$X_0$开始进行Metropolis采样。同时这些样本还具有权重：

$$
w = \frac{f(X_0)}{p(X_0)}
$$

如果$f(X_0)=0$，此时所有的样本权重均为0。为了解决这个问题我们可以从$p(x)$中采样出一系列初值的候选值$Y_1, Y_2, ..., Y_N$，每个候选值的权重为：

$$
w_i = \frac{f(Y_i)}{p(Y_i)}
$$

然后根据$Y_i$的权重抽样出初始值$X_0$进行Metropolis采样即可，此时采样出的样本权重均为$w_i$的平均值。

### 1D Setting

接下来我们看一个实际的例子。假设$f(x)$的表达式为：

$$
f(x) = 
\left\{
\begin{aligned}
& (x - 0.5)^2 & & 0 \leq x \lt 1 \\
& 0           & & \text{otherwise} \\
\end{aligned}
\right.
$$

$f(x)$的函数图像可见下图。为了展示Metropolis采样的能力，这里假装$f(x)$是一个黑盒：我们可以对$f(x)$进行求值，但不知道具体的解析式。

<div align=center>
<img src="https://pbr-book.org/3ed-2018/Monte_Carlo_Integration/metro-func.svg" width="40%">
</div>

下面考虑两种不同的突变策略。第一个策略是直接从[0, 1]均匀分布上采样一个新的样本，在这种情况下我们有：

$$
X' = \xi
$$

$$
T_1(X \rightarrow X') = 1
$$

第二个策略是对$X$进行一个随机扰动，扰动的大小是0.05：

$$
X' = X + 0.1 (\xi - 0.5)
$$

$$
T_2(X \rightarrow X') = 
\left\{
\begin{aligned}
& \frac{1}{0.1} & &\vert X' - X \vert \leq 0.05 \\
& 0             & &\text{otherwise} \\
\end{aligned}
\right.
$$

对于初值$X_0$，我们直接从[0, 1]上的均匀分布进行采样：

$$
X_0 = \xi
$$

这样每个样本的权重均为$w = f(X_0)$。

然后我们就可以通过Metropolis采样来重建$f(x)$。由于在每次采样中我们都记录了两个样本$X$和$X'$以及它们对应的权重，在重建时可以通过直方图的方式来估计样本的概率密度，此时只需要对每个小区间内的样本权重进行求和即可。重建结果如下图所示，其中左图为单纯使用第一种突变策略的重建结果，而右图为混合使用两种突变策略的结果，其中有10%的概率选择第一个策略90%的概率选择第二个策略。


<div align=center>
<img src="https://pbr-book.org/3ed-2018/Monte_Carlo_Integration/metro-onestrategy.svg" width="40%">
<img src="https://pbr-book.org/3ed-2018/Monte_Carlo_Integration/metro-bothstrategies.svg" width="40%">
</div>

直观来看直接在均匀分布上进行采样并不是一个很好的策略。它的缺陷在于当函数值$f(x)$比较大时不能很好地利用该点的概率密度，仍会随机跳跃到其它区域上。尽管如此，在这种策略下Metropolis采样仍然能够收敛到正确的分布上。而混合策略则可以更好地近似$f(x)$对应的分布，这是由于此时的采样策略可以利用$f(x)$的函数值来移动到高概率的区间上。

如果单纯使用随机扰动作为突变则会得到下图所示的重建结果。其中左图是10,000个样本的重建结果，而右图是300,000个样本的结果。产生这种现象的原因在于当突变的步长比较小时样本很难从一侧跨越到曲线的另一侧，因此需要更多的采样次数才能得到合理的结果。

<div align=center>
<img src="https://pbr-book.org/3ed-2018/Monte_Carlo_Integration/metro-10k-1mutate.svg" width="40%">
<img src="https://pbr-book.org/3ed-2018/Monte_Carlo_Integration/metro-300k-1mutate.svg" width="40%">
</div>

### Estimating Integrals with Metropolis Sampling

利用Metropolis采样我们可以估计形如$\int f(x) g(x) \ d\Omega$的积分。利用Monte Carlo积分公式可以得到估计值：

$$
\int_\Omega f(x) g(x) \ d\Omega \approx \frac{1}{N} \sum_{i=1}^N \frac{f(X_i) g(X_i)}{p(X_i)}
$$

根据Metropolis采样，我们可以把$p(x)$取为$f(x)$。这样积分就等于：

$$
\int_\Omega f(x) g(x) \ d\Omega \approx \bigg[ \frac{1}{N} \sum_{i=1}^N g(X_i) \bigg] \int_\Omega f(x) \ d\Omega
$$

## Transforming between Distributions

## 2D Sampling with Multidimensional Transformations

## Russian Roulette and Splitting

## Careful Sample Placement

## Bias

## Importance Sampling

## Reference

- [13 Monte Carlo Integration](https://pbr-book.org/3ed-2018/Monte_Carlo_Integration)